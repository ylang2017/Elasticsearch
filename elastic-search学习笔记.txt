关键词解释
ElasticSearch:常被称为文档数据库，主要得益于其分布式特性和实时搜索能力。
         Cluster

 　　代表一个集群，集群中有多个节点，其中有一个为主节点，这个主节点是可以通过选举产生的，主从节点是对于集群内部来说的。es的一个概念就是去中心化，字面上理解就是无中心节点，这是对于集群外部来说的，因为从外部来看es集群，在逻辑上是个整体，你与任何一个节点的通信和与整个es集群通信是等价的。

 　　　　Shards

　　代表索引分片，es可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。构成分布式搜索。分片的数量只能在索引创建前指定，并且索引创建后不能更改。

 　　　　replicas

　　代表索引副本，es可以设置多个索引的副本，副本的作用一是提高系统的容错性，当某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高es的查询效率，es会自动对搜索请求进行负载均衡。

 　　　　Recovery

　　代表数据恢复或叫数据重新分布，es在有节点加入或退出时会根据机器的负载对索引分片进行重新分配，挂掉的节点重新启动时也会进行数据恢复。

索引分片：当一个索引存储了海量数据时，可以将其分割分别部署在不同的服务器（Node节点）上，实现高性能。
类似于分库的提升性能感觉，但内部实现了协同工作，拥有更好的可用性。查询时将查询信息发送至每个节点，然后ES
会将每个节点的查询结果进行合并，对于外部而言是无感的（不用关心分片的存在）。

副本：由于存在修改操作，当对一个索引进行修改时，修改操作直接作用在这个索引上（如果是多分片的情况下，直接作用
在某个分片上），假如修改导致数据丢失，则直接影响索引可用性。因此对每个索引（或分片）进行精准拷贝，备份就称为副本
，原始的分片称为主分片，一个主分片可以有0或若干副本。当主分片丢失时，副本将被提升为新的主分片。

分词：对一行数据记录进行拆分，将其分为若干词条。“我爱祖国”分为“我”，“爱”，“祖国”
尤其是对于中文，分词插件的优劣也影响查询效率。
正向索引：对数据进行分词，然后将分词存储为索引，标注出现频率及次数。
正向索引即使用记录（Document）对分词进行查找，找出其频次及出现位置，查询时需要遍历Document,
数据量大时效率很差。
反向索引：通过分词反向查找Document位置，优点是不需要遍历Document,直接通过分词和Document的
关系即可查找出对应Document。(实现方式还是不明，文档说能优化，暂时相信吧)



1.Node和Cluster
Elastic本质上是一个分布式数据库，允许多台服务器协同工作，每一台服务器上可以运行多个
Elastic实例。一个实例就称为一个节点（Node）,一组节点构成一个集群（Cluster）。

2.Index
Elastic会索引所有的字段，处理后写入一个反向索引，以备下次查找时使用。Elastic对数据进行管理
的顶层单位就是Index,它与单个数据库同义，此外Index的名称必须是小写的。
查看当前节点所有的Index:
$ curl -X GET 'http://localhost:9200/_cat/indices?v'

3.Document
已知Index与数据库同义，这里并没有提到“表”的概念，直接跳到了“记录”的概念，Index里的单条记录
就称为Document，Document使用json格式表示。此外也弱化了“列”的概念，一个Index里的Document甚至
不要求有相同的结构（json格式），但虽然未要求，保持相同结构可以提高搜索效率。
此外ES还可以对一个字段设置多个值，称为多值字段，如{name：123，name：346，age:12}

查看所有记录：
$ curl 'localhost:9200/Inex/Type/_search'

4.Type (注意！！！ES7.+中已移除type概念)
Document可以分组，这个含义有点像“表”的意思(Type+mapping)，相同逻辑的记录可以分为同一个组（Type）,但此
分组只是逻辑分组用于过滤Document的。特别要说明的是性质不同的数据（比如user和Job）
应该存为2个Index,而不是在一个Index里用两种Type表示，虽然可以做到但不利于提高搜索效率。
Type由名称和Mapping组成，type表示一类相似的document。
对于不同type的document,相同的字段类型必须一致。

列出当前节点每个Index包含的Type:
$ curl 'localhost:9200/_mapping?pretty=true'

mapping
每一个index都有一个mapping，mapping定义了索引中的每一个type和一些index相关的设置，描述了每一个field的数据类型。 


--根据规划，Elastic 6.x 版只允许每个 Index 包含一个 Type，7.x 版将会彻底移除 Type。--


5.新建和删除一个名为weather的Index
$ curl -X PUT 'localhost:9200/weather'
$ curl -X DELETE 'localhost:9200/weather'

6.查看安装插件的列表
# sudo /es安装目录/bin/elasticsearch-plugin list


7.分词器ik在es中的配置，目录是 /es安装目录/config/analysis-ik/IKAnalyzer.cfg.xml
当使用自定义词典后，自定义词典内的词条将不再被分词，而是视为一整个词条。
如原“我爱祖国”会被分词为“我”，“爱”，“祖国”，若使用自定义词条“我爱祖国”将被视为一个词。
更新自定义分词后需要重启ES（但使用远程分词修改后无需重启，每分钟会自动加载一次）。

远程分词使用需要注意：
1.该 http 请求需要返回两个头部(header)，一个是 Last-Modified，一个是 ETag，这两者都是字符串类型，只要有一个发生变化，该插件就会去抓取新的分词进而更新词库。
2.该 http 请求返回的内容格式是一行一个分词，换行符用 \n 即可。

<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
<properties>
        <!--配置文件名称,表明整个配置文件的目的即可,保持默认挺好的 -->
        <comment>IK Analyzer 扩展配置</comment>  
        <!--用户可以在这里配置自己的扩展字典,使用相对路径,多个词典使用逗号分隔,比如:custom/mydict1.dic,custom/mydict2.dic -->
        <entry key="ext_dict"></entry>
         <!--用户可以在这里配置自己的扩展停止词字典,使用相对路径,多个词典使用逗号分隔,比如:custom/mydict1.dic,custom/mydict2.dic -->
        <entry key="ext_stopwords"></entry>
        <!--用户可以在这里配置远程扩展字典,配置远程扩展字典,多个词典使用逗号分隔,比如: http://xxx.xx.com/xxx -->
        <entry key="remote_ext_dict">words_location</entry>
        <!--用户可以在这里配置远程扩展停止词字典,多个词典使用逗号分隔,比如: http://xxx.xx.com/xxx -->
        <entry key="remote_ext_stopwords">words_location</entry>
</properties>


8.全文索引

$ curl 'localhost:9200/Index/Type/_search'  -d '
{
  "query" : { "match" : { "desc" : "管理" }},
  "from": 1,
  "size": 1
}'
语句含义：
	使用 Match 查询，指定的匹配条件是desc字段里面包含"管理"这个词。
	from:如果有多条记录，from用于指定偏移（默认从0开始）。
	size:指定返回记录条数。

逻辑或查询： 
 "query" : { "match" : { "desc" : "管理 软件" }},
查询包含“管理”或“软件”的记录。

逻辑与查询：
"query": {
  "bool": {
    "must": [
	  { "match": { "desc": "软件" } },
	  { "match": { "desc": "管理" } }
    ]
  }
}


https://elasticsearch.thans.cn/downloads/elasticsearch/elasticsearch-7.3.1-windows-x86_64.zip
https://artifacts.elastic.co/downloads/kibana/kibana-7.7.0-windows-x86_64.zip
elasticsearch-7.7.0-windows-x86_64.zip


"No handler for type [string] declared on field [description]"
报错原因
我使用的Elasticsearch是6.2.2版本，按照学习文档创建字段时，使用了{"type":"string","index":"not_analyzed"}。

原因分析
检查拼写无误之后，我决定去查Elasticsearch新版本特性，因为之前也踩过head插件的安装方法的坑，就是因为版本问题。
果不其然，Elasticsearch从5.X就引入了text和keyword，其中keyword适用于不分词字段，搜索时只能完全匹配，这时string还保留着。
到了6.X就彻底移除string了。
另外，"index"的值只能是boolean变量了。title.store也是boolean

解决方法
{"type":"text","index":false}


9.查询时经常会看到?pretty参数，此参数是用于美化响应数据的，因为返回的是json数据，加上此参数会自动为json换行。

10.创建索引结构（mappings）时，一些通用属性介绍：
index:boolean,此字段是否用于索引（是不是可以被搜索）默认true
store:boolean，此字段的原始值是否存入索引。默认false
type:string,此字段的数据类型，必须是es支持的类型

11.在为索引创建mapping时指定dynamic为false,即可禁止其它操作添加非mapping指定的字段。









SpringBoot是2.2.0.RELEASE才兼容elasticsearch 7.x


